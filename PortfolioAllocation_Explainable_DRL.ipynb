{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b18ff48-b58d-459a-b946-363345abbd61",
   "metadata": {},
   "source": [
    "## install finrl library\n",
    "!pip install plotly==4.4.1\n",
    "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
    "!chmod +x /usr/local/bin/orca\n",
    "!apt-get install xvfb libgtk2.0-0 libgconf-2-4\n",
    "!pip install wrds\n",
    "!pip install swig\n",
    "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
    "!pip install PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a320f4a7-15fb-42ee-85cd-ca62477e4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a282e71-ce5b-4a4e-92e6-9da68a284792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (100385, 8)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "from preprocessor.yahoodownloader import YahooDownloader\n",
    "\n",
    "df = YahooDownloader(start_date = '2008-01-01',\n",
    "                     end_date = '2021-09-02',\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()\n",
    "print(len(df.tic.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0459c4d-5c00-4bda-91ec-bcf3dd201002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>5.855758</td>\n",
       "      <td>6.018652</td>\n",
       "      <td>5.786934</td>\n",
       "      <td>5.988898</td>\n",
       "      <td>1079178800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>32.223785</td>\n",
       "      <td>32.528046</td>\n",
       "      <td>31.988676</td>\n",
       "      <td>32.223785</td>\n",
       "      <td>7934400</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>38.898682</td>\n",
       "      <td>39.874196</td>\n",
       "      <td>38.708151</td>\n",
       "      <td>39.698909</td>\n",
       "      <td>8053700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>63.481640</td>\n",
       "      <td>64.375743</td>\n",
       "      <td>63.027255</td>\n",
       "      <td>64.177869</td>\n",
       "      <td>4303000</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>44.507305</td>\n",
       "      <td>45.792806</td>\n",
       "      <td>44.141823</td>\n",
       "      <td>45.723490</td>\n",
       "      <td>6337800</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        date      close       high        low       open      volume  \\\n",
       "0      2008-01-02   5.855758   6.018652   5.786934   5.988898  1079178800   \n",
       "1      2008-01-02  32.223785  32.528046  31.988676  32.223785     7934400   \n",
       "2      2008-01-02  38.898682  39.874196  38.708151  39.698909     8053700   \n",
       "3      2008-01-02  63.481640  64.375743  63.027255  64.177869     4303000   \n",
       "4      2008-01-02  44.507305  45.792806  44.141823  45.723490     6337800   \n",
       "\n",
       "Price   tic  day  \n",
       "0      AAPL    2  \n",
       "1      AMGN    2  \n",
       "2       AXP    2  \n",
       "3        BA    2  \n",
       "4       CAT    2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd0c55e-f5e7-47a4-99d7-e585b12edc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b789dbb-2250-430d-bf11-242015dea84f",
   "metadata": {},
   "source": [
    "TO-DO:\n",
    "\n",
    "1. understand what FeatureEngineer methods are used on this dataframe\n",
    "2. what technical indicators are used\n",
    "3. what is turbulence index and how is it calculated\n",
    "4. data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8089cdb-0d23-462b-b638-b2af9eddb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, start, end, target_date_col=\"date\"):\n",
    "    \"\"\"\n",
    "    split the dataset into training or testing using date\n",
    "    :param data: (df) pandas dataframe, start, end\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
    "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
    "    data.index = data[target_date_col].factorize()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03b24f-600b-48d7-b60b-36c3acdab2e2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "\n",
    "# Sample stock data\n",
    "data = pd.DataFrame({\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05',\n",
    "             '2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'tic': ['AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL',\n",
    "            'MSFT', 'MSFT', 'MSFT', 'MSFT', 'MSFT'],\n",
    "    'open': [145.0, 147.0, 149.0, 151.0, 153.0,\n",
    "             240.0, 242.0, 244.0, 246.0, 248.0],\n",
    "    'high': [148.0, 150.0, 152.0, 154.0, 156.0,\n",
    "             243.0, 245.0, 247.0, 249.0, 251.0],\n",
    "    'low': [144.0, 146.0, 148.0, 150.0, 152.0,\n",
    "            239.0, 241.0, 243.0, 245.0, 247.0],\n",
    "    'close': [147.0, 149.0, 151.0, 153.0, 155.0,\n",
    "              242.0, 244.0, 246.0, 248.0, 250.0],\n",
    "    'volume': [1000000, 1100000, 1200000, 1300000, 1400000,\n",
    "               800000, 850000, 900000, 950000, 1000000]\n",
    "})\n",
    "\n",
    "# Let's say we want to add these technical indicators\n",
    "# tech_indicator_list = ['macd', 'rsi_30', 'cci_30', 'dx_30']\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f549d8e-38bb-4a1d-b247-bbd0cf67141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from stockstats import StockDataFrame as sdf\n",
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    Provides methods for preprocessing stock price data.\n",
    "\n",
    "    method:\n",
    "    preprocess_data(): main method to feature engineering\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_technical_indicator=True,\n",
    "        tech_indicator_list=config.INDICATORS,\n",
    "        use_vix=False,\n",
    "        use_turbulence=False,\n",
    "        user_defined_feature=False,\n",
    "    ):\n",
    "        self.use_technical_indicator = use_technical_indicator\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.use_vix = use_vix\n",
    "        self.use_turbulence = use_turbulence\n",
    "        self.user_defined_feature = user_defined_feature\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Main method for feature engineering.\n",
    "        @:param config: source dataframe\n",
    "        @:return: a DataMatrices object\n",
    "        \"\"\"\n",
    "        df = self.clean_data(df)\n",
    "\n",
    "        if self.use_technical_indicator:\n",
    "            df = self.add_technical_indicator(df)\n",
    "            print(\"Successfully added technical indicators from FinRl library configuration!\\n\")\n",
    "            print(f\"Indicator list: {self.tech_indicator_list}\")\n",
    "\n",
    "        if self.use_vix:\n",
    "            df=self.add_vix(df)\n",
    "            print(\"Successfully added vix!\")\n",
    "            \n",
    "        if self.use_turbulence:\n",
    "            df = self.add_turbulence(df)\n",
    "            print(\"Successfully added turbulence index!\")\n",
    "            \n",
    "        if self.user_defined_feature:\n",
    "            df = self.add_user_defined_feature(df)\n",
    "            print(\"Successfully added user defined features!\")\n",
    "            \n",
    "        df = df.ffill().bfill()\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        \"\"\"\n",
    "        Data sorting, index transformation, pivot table creation, data cleaning, filtering.\n",
    "        \n",
    "        Any stock that has any missing values on any date will be completely dropped from the dataset.\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "\n",
    "        # sort the data frame by chronological date first, and by ticker in alphebatical order, change index after sorting. \n",
    "        df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "\n",
    "        # set index of this data frame equivalent to represent unique dates\n",
    "        # codes, unique_values = df.date.factorize()\n",
    "        df.index = df.date.factorize()[0]\n",
    "        # print(\"codes: \", codes)\n",
    "        # print(\"unique values: \", unique_values)\n",
    "\n",
    "        # create a pivot table from original one\n",
    "        merge_close_df = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "\n",
    "        # observe there are missing values in 'TSLA' on '2003-01-02' and '2003-01-03'\n",
    "        merge_close_df = merge_close_df.dropna(axis=1) #drop the entire column\n",
    "        tics = merge_close_df.columns\n",
    "        \n",
    "        # this filters the tic column by keeping the rows exist in 'tics' variable\n",
    "        df = df[df.tic.isin(tics)] \n",
    "        \n",
    "        return df\n",
    "\n",
    "    # from stockstats import StockDataFrame as sdf\n",
    "    def add_technical_indicator(self, data):\n",
    "        \"\"\"\n",
    "        Transform basic OHLCV data \n",
    "        into a comprehensive dataset with technical analysis indicators \n",
    "        that help RL agents make better trading decisions.\n",
    "        \n",
    "        param: data is pd.DataFrame\n",
    "        return: df \n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df = df.sort_values(by=[\"tic\", \"date\"])\n",
    "\n",
    "        # converts to a copy of df into StockDataFrame\n",
    "        stock = sdf.retype(df.copy()) # it's still the same df, but can calculate technical indicators\n",
    "        unique_ticker = stock.tic.unique()\n",
    "\n",
    "        for indicator in self.tech_indicator_list:\n",
    "            # print(\"indicators in the list: \\n\", self.tech_indicator_list)\n",
    "            indicator_df = pd.DataFrame()\n",
    "            \n",
    "            for i, ticker in enumerate(unique_ticker):\n",
    "                # note: ticker value is within the stock dataframe tic column\n",
    "                stock_data = stock[stock.tic == ticker]\n",
    "                \n",
    "                # print(f\"Stock data for {ticker}: \\n\", stock_data['close'])\n",
    "                # print(f\"Entire stock data: \\n\", stock_data)\n",
    "                \n",
    "                try:\n",
    "                    # print(f\"Current indicator: {indicator} for ticker: {ticker}\\n\")\n",
    "\n",
    "                    # this creates a new series with a single column in stock_data sdf called temp_indicator, turned into pd.DataFrame\n",
    "                    temp_indicator = stock_data[indicator] # this triggers sdf calculation based on this specific stock OHLCV value\n",
    "                    temp_indicator = pd.DataFrame(temp_indicator) # Series -> df\n",
    "                    \n",
    "                    # print(f\"\\nCalculated {indicator} for {ticker}:\")\n",
    "                    # print(temp_indicator)\n",
    "                    \n",
    "                    # add columns tic, date to temp_indicator, for context\n",
    "                    temp_indicator[\"tic\"] = ticker \n",
    "                    temp_indicator[\"date\"] = df[df.tic == ticker][\"date\"].to_list()\n",
    "                    \n",
    "                    # print(f\"\\nwith metadata added: \")\n",
    "                    # print(temp_indicator)\n",
    "\n",
    "                    #concatenate the modified temp_indicator df to indicator_df\n",
    "                    # axis=0, stack vertically\n",
    "                    # done accumulatively from each stock df information stored in temp_indicator\n",
    "                    indicator_df = pd.concat(\n",
    "                        [indicator_df, temp_indicator], axis=0, ignore_index=True\n",
    "                    )\n",
    "                    # print(\"Indicator df: \\n\", indicator_df)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    \n",
    "            # merge the df based on \"tic\", \"date\", effecively add indicator value with context to the original df\n",
    "            df = df.merge(\n",
    "                indicator_df[[\"tic\",\"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
    "            )\n",
    "            # print(\"After merge:\\n\", df)\n",
    "            \n",
    "            df = df.sort_values(by=[\"date\", \"tic\"])\n",
    "            \n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411bbe8-e0ef-47ae-82f4-702a6c02badd",
   "metadata": {},
   "source": [
    "### use_technical_indicator test case\n",
    "feaureEngineer_techindicator = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    use_turbulence=True,\n",
    "    user_defined_feature=False)\n",
    "\n",
    "feaureEngineer_techindicator.add_technical_indicator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f09cf219-ff9d-4a89-af0e-3dd818805feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators from FinRl library configuration!\n",
      "\n",
      "Indicator list: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "28\n",
      "             date       close        high         low        open      volume  \\\n",
      "0      2008-01-02    5.855758    6.018652    5.786934    5.988898  1079178800   \n",
      "1      2008-01-02   32.223785   32.528046   31.988676   32.223785     7934400   \n",
      "2      2008-01-02   38.898682   39.874196   38.708151   39.698909     8053700   \n",
      "3      2008-01-02   63.481640   64.375743   63.027255   64.177869     4303000   \n",
      "4      2008-01-02   44.507305   45.792806   44.141823   45.723490     6337800   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "96371  2021-09-01  146.831177  147.706925  145.844812  146.969448     1133800   \n",
      "96372  2021-09-01  392.533875  394.904022  386.787168  391.772040     2034400   \n",
      "96373  2021-09-01   43.478058   43.644249   43.367266   43.525541    12647300   \n",
      "96374  2021-09-01   41.053249   41.477741   40.392021   41.412434     5212400   \n",
      "96375  2021-09-01   46.772121   46.819599   46.389160   46.702495    19056600   \n",
      "\n",
      "        tic  day    macd_x   boll_ub_x  ...  close_30_sma_x  close_60_sma_x  \\\n",
      "0      AAPL    2  0.000000    5.860930  ...        5.855758        5.855758   \n",
      "1      AMGN    2  0.000000    5.860930  ...       32.223785       32.223785   \n",
      "2       AXP    2  0.000000    5.860930  ...       38.898682       38.898682   \n",
      "3        BA    2  0.000000    5.860930  ...       63.481640       63.481640   \n",
      "4       CAT    2  0.000000    5.860930  ...       44.507305       44.507305   \n",
      "...     ...  ...       ...         ...  ...             ...             ...   \n",
      "96371   TRV    2  1.971370  151.545836  ...      142.781192      141.273363   \n",
      "96372   UNH    2  1.458220  404.443679  ...      391.793026      386.415219   \n",
      "96373    VZ    2 -0.197174   44.439722  ...       43.903028       44.091656   \n",
      "96374   WBA    2  0.400513   41.212689  ...       38.988199       39.771525   \n",
      "96375   WMT    2  0.394082   48.226035  ...       46.295596       45.117389   \n",
      "\n",
      "         macd_y   boll_ub_y   boll_lb_y    rsi_30_y    cci_30_y     dx_30_y  \\\n",
      "0      0.000000    5.860930    5.853287  100.000000  -66.666667  100.000000   \n",
      "1      0.000000    5.860930    5.853287  100.000000  -66.666667  100.000000   \n",
      "2      0.000000    5.860930    5.853287  100.000000  -66.666667  100.000000   \n",
      "3      0.000000    5.860930    5.853287  100.000000  -66.666667  100.000000   \n",
      "4      0.000000    5.860930    5.853287  100.000000  -66.666667  100.000000   \n",
      "...         ...         ...         ...         ...         ...         ...   \n",
      "96371  1.971370  151.545836  139.691103   55.446837   62.497337   23.393182   \n",
      "96372  1.458220  404.443679  380.180088   53.065147   -4.010975   15.765699   \n",
      "96373 -0.197174   44.439722   43.098850   44.243152 -102.773382   22.856844   \n",
      "96374  0.400513   41.212689   37.819142   54.782478  156.805637   25.105229   \n",
      "96375  0.394082   48.226035   45.734563   57.098526   24.428396    8.809568   \n",
      "\n",
      "       close_30_sma_y  close_60_sma_y  \n",
      "0            5.855758        5.855758  \n",
      "1           32.223785       32.223785  \n",
      "2           38.898682       38.898682  \n",
      "3           63.481640       63.481640  \n",
      "4           44.507305       44.507305  \n",
      "...               ...             ...  \n",
      "96371      142.781192      141.273363  \n",
      "96372      391.793026      386.415219  \n",
      "96373       43.903028       44.091656  \n",
      "96374       38.988199       39.771525  \n",
      "96375       46.295596       45.117389  \n",
      "\n",
      "[96376 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    use_turbulence=False,\n",
    "    user_defined_feature=False)\n",
    "\n",
    "# df = fe.preprocess_data(data)\n",
    "df = fe.preprocess_data(df)\n",
    "\n",
    "print(len(df.tic.unique()))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610e30d-5575-4021-a0c7-073be1fb42f2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original messy data\n",
    "data = pd.DataFrame({\n",
    "    'date': ['2023-01-03', '2023-01-01', '2023-01-02', '2023-01-03', \n",
    "             '2023-01-01', '2023-01-02', '2023-01-01', '2023-01-03'],\n",
    "    'tic': ['AAPL', 'AAPL', 'AAPL', 'MSFT', 'MSFT', 'MSFT', 'TSLA', 'TSLA'],\n",
    "    'close': [150.0, 145.0, 148.0, 250.0, 245.0, 248.0, 800.0, np.nan]\n",
    "})\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffd5af-7bde-4aee-a521-24f80d2f8a9c",
   "metadata": {},
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb96605-91c5-4b0a-bb61-5d9b374f9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a7c1f-3bd0-4a6e-b38b-faee5bf070b6",
   "metadata": {},
   "source": [
    "### Add covariance matrix as states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f00eb3c-0dda-40b9-9e9e-93492d6739e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (626628075.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[42], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    return_lookback price_lookback.pct_change().dropna()\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# add covariance matrix as states\n",
    "\n",
    "# returns the first tuple\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback = 252\n",
    "for i in range(lookback, len(df.index.unique())):\n",
    "    data_lookback = df.loc[i-lookback: i, :]\n",
    "    price_lookback= data_lookback.pivot_table(index= 'date', columns= 'tic', values='close')\n",
    "    return_lookback price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    covs = return_lookback.cov().values\n",
    "    cov_list.append(covs)\n",
    "\n",
    "df_cov = pd.DataFrame({'date': df.date.unique()[lookback:], \n",
    "                       'cov_list':cov_list, \n",
    "                       'return_list': return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date', 'tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5906bbd-0a7e-4144-9f8b-1462c56db0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2343, 3)\n",
      "Date range: 2021-01-01 00:00:00 to 2023-12-29 00:00:00\n",
      "Unique dates: 781\n",
      "Unique tickers: ['AAPL' 'MSFT' 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simulate 3 years of daily data for 3 stocks (2021-2023)\n",
    "dates = pd.date_range('2021-01-01', '2023-12-31', freq='D')\n",
    "dates = [d for d in dates if d.weekday() < 5]  # Business days only\n",
    "\n",
    "# Create sample data\n",
    "data_rows = []\n",
    "tickers = ['AAPL', 'MSFT', 'TSLA']\n",
    "\n",
    "for date in dates:\n",
    "    for ticker in tickers:\n",
    "        # Simulate price data\n",
    "        base_price = {'AAPL': 150, 'MSFT': 250, 'TSLA': 800}[ticker]\n",
    "        noise = np.random.normal(0, 0.02)  # 2% daily volatility\n",
    "        price = base_price * (1 + noise)\n",
    "        \n",
    "        data_rows.append({\n",
    "            'date': date,\n",
    "            'tic': ticker, \n",
    "            'close': price\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data_rows)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df.date.min()} to {df.date.max()}\")\n",
    "print(f\"Unique dates: {len(df.date.unique())}\")\n",
    "print(f\"Unique tickers: {df.tic.unique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
